"""
æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆRAGï¼‰

pos ä»¥å‰ã®ãƒãƒ£ãƒ³ã‚¯ã®ã¿ã‚’æ¤œç´¢å¯¾è±¡ã¨ã—ã€ãƒã‚¿ãƒãƒ¬ã‚’é˜²æ­¢
"""

import logging
import re
import threading
from typing import List, Dict, Any, Optional, Tuple

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

from app.utils import get_chunks_cache, get_events_cache, embed, chat

logger = logging.getLogger(__name__)

# Qdrant ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰
_qdrant_client = None
COLLECTION_NAME = "neko_scenes"

# çŠ¶æ³è¦ç´„ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆpos, character_name -> è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆï¼‰
_situation_cache: Dict[Tuple[int, str], str] = {}
_situation_locks: Dict[Tuple[int, str], threading.Event] = {}
_situation_locks_guard = threading.Lock()


def get_qdrant_client():
    """Qdrant ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰"""
    global _qdrant_client
    if _qdrant_client is None:
        try:
            from qdrant_client import QdrantClient
            _qdrant_client = QdrantClient(host="localhost", port=6333)
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            _qdrant_client.get_collections()
            logger.info("âœ“ Qdrant æ¥ç¶šæˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸  Qdrant æ¥ç¶šå¤±æ•—: {e}")
            _qdrant_client = False  # å¤±æ•—ã‚’è¨˜éŒ²
    return _qdrant_client if _qdrant_client is not False else None


def find_current_scene(pos: int) -> Optional[int]:
    """pos ã‚’å«ã‚€/æœ€ã‚‚è¿‘ã„ãƒãƒ£ãƒ³ã‚¯ã® scene_index ã‚’è¿”ã™"""
    chunks = get_chunks_cache()

    # pos ã‚’å«ã‚€ãƒãƒ£ãƒ³ã‚¯ã‚’æ¢ã™
    for chunk in chunks:
        if chunk["start_pos"] <= pos <= chunk["end_pos"]:
            return chunk["scene_index"]

    # å«ã¾ã‚Œãªã„å ´åˆã€æœ€ã‚‚è¿‘ã„ãƒãƒ£ãƒ³ã‚¯ã‚’æ¢ã™
    closest = min(chunks, key=lambda c: abs(c["start_pos"] - pos))
    return closest["scene_index"]


def retrieve_nearby(scene: int, window: int = 3) -> List[Dict[str, Any]]:
    """scene ã®å‰å¾Œ window ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—"""
    chunks = get_chunks_cache()

    nearby = []
    for chunk in chunks:
        if scene - window <= chunk["scene_index"] <= scene + window:
            nearby.append(chunk)

    return nearby


def search_semantic_qdrant(
    query_vec: List[float],
    k: int,
    max_pos: int
) -> Optional[List[Dict[str, Any]]]:
    """Qdrant ã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆpos ãƒ•ã‚£ãƒ«ã‚¿ä»˜ãï¼‰"""
    client = get_qdrant_client()
    if client is None:
        return None

    try:
        from qdrant_client.models import FieldCondition, Filter, Range

        # max_pos ã‚’å«ã‚€ãƒãƒ£ãƒ³ã‚¯ã€ã¾ãŸã¯ max_pos ä»¥å‰ã§çµ‚ã‚ã‚‹ãƒãƒ£ãƒ³ã‚¯
        # start_pos <= max_pos ã®ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆend_pos <= max_pos ã¾ãŸã¯ start_pos <= max_pos <= end_posï¼‰
        query_filter = Filter(
            must=[
                FieldCondition(
                    key="start_pos",
                    range=Range(lte=max_pos)
                )
            ]
        )

        results = client.search(
            collection_name=COLLECTION_NAME,
            query_vector=query_vec,
            query_filter=query_filter,
            limit=k
        )

        chunks = []
        for hit in results:
            chunk_data = {
                "scene_index": hit.payload["scene_index"],
                "chapter": hit.payload["chapter"],
                "start_pos": hit.payload["start_pos"],
                "end_pos": hit.payload["end_pos"],
                "text": hit.payload["text"],
                "characters": hit.payload.get("characters", []),
                "score": hit.score
            }
            chunks.append(chunk_data)

        logger.info(f"âœ“ Qdrant æ¤œç´¢: {len(chunks)} ä»¶å–å¾—")
        return chunks

    except Exception as e:
        logger.error(f"âŒ Qdrant æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def search_semantic_fallback(
    query_vec: List[float],
    k: int,
    max_pos: int
) -> List[Dict[str, Any]]:
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢"""
    chunks = get_chunks_cache()

    # max_pos ã‚’å«ã‚€ãƒãƒ£ãƒ³ã‚¯ã€ã¾ãŸã¯ max_pos ä»¥å‰ã§çµ‚ã‚ã‚‹ãƒãƒ£ãƒ³ã‚¯
    candidates = [c for c in chunks if c["start_pos"] <= max_pos <= c["end_pos"] or c["end_pos"] <= max_pos]

    if not candidates:
        logger.warning("âš ï¸  max_pos ä»¥å‰ã®ãƒãƒ£ãƒ³ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“")
        return []

    # å„ãƒãƒ£ãƒ³ã‚¯ã‚’åŸ‹ã‚è¾¼ã¿
    logger.info(f"ğŸ“Š ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢: {len(candidates)} ä»¶ã‹ã‚‰åŸ‹ã‚è¾¼ã¿è¨ˆç®—ä¸­...")
    chunk_vecs = []
    for chunk in candidates:
        try:
            vec = embed(chunk["text"][:500])  # å…ˆé ­500æ–‡å­—
            chunk_vecs.append(vec)
        except Exception as e:
            logger.error(f"åŸ‹ã‚è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            chunk_vecs.append([0.0] * len(query_vec))  # ãƒ€ãƒŸãƒ¼

    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
    query_vec_np = np.array(query_vec).reshape(1, -1)
    chunk_vecs_np = np.array(chunk_vecs)

    similarities = cosine_similarity(query_vec_np, chunk_vecs_np)[0]

    # ä¸Šä½ k ä»¶
    top_indices = np.argsort(similarities)[::-1][:k]

    results = []
    for idx in top_indices:
        chunk = candidates[idx].copy()
        chunk["score"] = float(similarities[idx])
        results.append(chunk)

    logger.info(f"âœ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢: {len(results)} ä»¶å–å¾—")
    return results


def expand_query_with_history(
    question: str,
    history: List[Dict[str, str]] = None,
    character_name: str = None,
    pos: int = None
) -> str:
    """
    ä¼šè©±å±¥æ­´ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã€ãƒ†ã‚­ã‚¹ãƒˆä½ç½®ã‚’è€ƒæ…®ã—ã¦è³ªå•ã‚’æ‹¡å¼µãƒ»ãƒªãƒ©ã‚¤ãƒˆ

    Args:
        question: ç¾åœ¨ã®è³ªå•
        history: ä¼šè©±å±¥æ­´ [{"role": "user/assistant", "content": "..."}]
        character_name: å¯¾è©±ç›¸æ‰‹ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åï¼ˆä¾‹: "å¾è¼©"ï¼‰
        pos: ç¾åœ¨ã®ãƒ†ã‚­ã‚¹ãƒˆä½ç½®

    Returns:
        æ‹¡å¼µã•ã‚ŒãŸè³ªå•æ–‡
    """
    if not question or len(question.strip()) == 0:
        return question

    # ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—ï¼ˆæœ€å¤§3ã‚¿ãƒ¼ãƒ³ï¼6ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
    recent_history = []
    if history and len(history) > 0:
        recent_history = history[-6:] if len(history) > 6 else history

    # å±¥æ­´ã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã‚’å«ã‚ã‚‹ï¼‰
    history_context = ""
    for msg in recent_history:
        char_name = msg.get("character_name")
        if msg.get("role") == "user":
            role_label = "ãƒ¦ãƒ¼ã‚¶ãƒ¼"
        elif char_name:
            role_label = char_name  # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼åã‚’ä½¿ç”¨
        else:
            role_label = "ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼"

        content = msg.get("content", "")
        if content:
            history_context += f"{role_label}: {content}\n"

    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã®å–å¾—
    from app.utils import get_personas_cache
    personas = get_personas_cache()
    character_info = ""
    if character_name and character_name in personas:
        persona = personas[character_name]
        character_info = f"\nå¯¾è©±ç›¸æ‰‹: {character_name}\n"
        # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®é–¢ä¿‚æ€§æƒ…å ±ã‚’è¿½åŠ 
        if character_name == "å¾è¼©":
            character_info += "ï¼ˆå¾è¼©ã®å®¶ä¸»ã¯ã€Œè‹¦æ²™å¼¥å…ˆç”Ÿã€ã€å«Œã„ãªäººç‰©ã¯ã€ŒãŠã•ã‚“ã€ã€å‹äººã«ã€Œè»Šå±‹ã®é»’ã€ãªã©ãŒã„ã‚‹ï¼‰"

    # ç¾åœ¨ä½ç½®ä»˜è¿‘ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ï¼ˆæ–‡è„ˆã®ãŸã‚ï¼‰
    position_context = ""
    if pos is not None:
        from app.utils import get_text_around_position
        nearby_text = get_text_around_position(pos, context_chars=100)
        if nearby_text:
            position_context = f"\nç¾åœ¨ã®ãƒ†ã‚­ã‚¹ãƒˆä½ç½®ä»˜è¿‘: {nearby_text}\n"

    # LLMã‚’ä½¿ã£ã¦è³ªå•ã‚’æ‹¡å¼µãƒ»ãƒªãƒ©ã‚¤ãƒˆ
    try:
        system_prompt = """ã‚ãªãŸã¯æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ”¹å–„ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä¼šè©±å±¥æ­´ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã€ãƒ†ã‚­ã‚¹ãƒˆä½ç½®ã‚’è€ƒæ…®ã—ã¦ã€å°èª¬æœ¬æ–‡ã®æ¤œç´¢ã«æœ€é©ãªè³ªå•æ–‡ã«ãƒªãƒ©ã‚¤ãƒˆã—ã¦ãã ã•ã„ã€‚

é‡è¦ãªå‡¦ç†ï¼š
1. **ä»£åè©ãƒ»çœç•¥ã•ã‚ŒãŸä¸»èªã®è§£æ±º**:
   - ã€Œå®¶ä¸»ã€â†’ã€Œè‹¦æ²™å¼¥å…ˆç”Ÿã€ã®ã‚ˆã†ã«ã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é–¢ä¿‚ã‚’è€ƒæ…®
   - ã€Œãã‚Œã€ã€Œã‚ã‚Œã€â†’ ä¼šè©±å±¥æ­´ã‹ã‚‰å…·ä½“çš„ãªå¯¾è±¡ã‚’ç‰¹å®š

2. **æ™‚é–“è¡¨ç¾ã®å…·ä½“åŒ–**:
   - ã€Œæœ€è¿‘ã€â†’ã€Œç¾åœ¨ã®ãƒ†ã‚­ã‚¹ãƒˆä½ç½®ä»˜è¿‘ã§ã€
   - ã€Œãã®å¾Œã€â†’ã€Œãã®å‡ºæ¥äº‹ã®å¾Œã§ã€

3. **æ–‡è„ˆå‚ç…§ã®è§£æ±º**:
   - ã€Œå…·ä½“çš„ã«ã¯ï¼Ÿã€â†’ ç›´å‰ã®è©±é¡Œã‚’å«ã‚ãŸè³ªå•ã«å¤‰æ›
   - ã€Œãªãœï¼Ÿã€â†’ ä½•ã«ã¤ã„ã¦ã®ã€Œãªãœã€ã‹ã‚’æ˜ç¢ºåŒ–

4. **æ¤œç´¢ã«é©ã—ãŸå½¢å¼**:
   - æœ¬æ–‡ä¸­ã«ç™»å ´ã™ã‚‹è¨€è‘‰ã‚’ä½¿ã†
   - ç°¡æ½”ã§å…·ä½“çš„ï¼ˆ30-60æ–‡å­—ç¨‹åº¦ï¼‰
   - æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹

å‡ºåŠ›ã¯æ‹¡å¼µã•ã‚ŒãŸè³ªå•æ–‡ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"""

        user_message = f"""ä»¥ä¸‹ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€è³ªå•ã‚’æ¤œç´¢ã«é©ã—ãŸå½¢ã«ãƒªãƒ©ã‚¤ãƒˆã—ã¦ãã ã•ã„ã€‚

{character_info}
{position_context}
ä¼šè©±å±¥æ­´:
{history_context if history_context else "ï¼ˆãªã—ï¼‰"}

ç¾åœ¨ã®è³ªå•: {question}

ãƒªãƒ©ã‚¤ãƒˆã•ã‚ŒãŸè³ªå•:"""

        expanded = chat(
            messages=[{"role": "user", "content": user_message}],
            system=system_prompt,
            temperature=0.2,  # 0.3â†’0.2 ã‚ˆã‚Šæ±ºå®šçš„ã«
            max_tokens=150
        )

        expanded = expanded.strip()
        # å¼•ç”¨ç¬¦ã‚’é™¤å»
        expanded = expanded.strip('"').strip("'").strip("ã€Œ").strip("ã€")

        if expanded and len(expanded) > 5:  # æœ‰åŠ¹ãªçµæœã®å ´åˆ
            logger.info(f"ğŸ“ è³ªå•æ‹¡å¼µ: '{question}' â†’ '{expanded}'")
            return expanded
        else:
            logger.warning(f"âš ï¸  è³ªå•æ‹¡å¼µçµæœãŒçŸ­ã™ãã‚‹: '{expanded}'")
    except Exception as e:
        logger.warning(f"âš ï¸  è³ªå•æ‹¡å¼µã‚¨ãƒ©ãƒ¼: {e}")

    return question


def search_keyword(
    query: str,
    k: int,
    max_pos: int
) -> List[Dict[str, Any]]:
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆç°¡æ˜“ç‰ˆï¼šãƒ†ã‚­ã‚¹ãƒˆå†…ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ï¼‰
    
    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        k: å–å¾—ä»¶æ•°
        max_pos: æœ€å¤§ä½ç½®
    
    Returns:
        æ¤œç´¢çµæœãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
    """
    chunks = get_chunks_cache()
    
    # max_posä»¥å‰ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    candidates = [c for c in chunks if c["start_pos"] <= max_pos]
    
    if not candidates:
        return []
    
    # ã‚¯ã‚¨ãƒªã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆæ—¥æœ¬èªã®å˜èªå¢ƒç•Œã‚’è€ƒæ…®ï¼‰
    keywords = []
    # åè©ã‚„é‡è¦ãã†ãªå˜èªã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼š2æ–‡å­—ä»¥ä¸Šã®é€£ç¶šæ–‡å­—ï¼‰
    words = re.findall(r'[ä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ³]{2,}', query)
    keywords.extend(words)
    
    # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å‡ºç¾å›æ•°ï¼‰
    scored_chunks = []
    for chunk in candidates:
        text = chunk.get("text", "")
        score = 0
        matched_keywords = []
        
        for keyword in keywords:
            count = text.count(keyword)
            if count > 0:
                score += count
                matched_keywords.append(keyword)
        
        if score > 0:
            chunk_copy = chunk.copy()
            chunk_copy["score"] = float(score)
            chunk_copy["matched_keywords"] = matched_keywords
            scored_chunks.append(chunk_copy)
    
    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    scored_chunks.sort(key=lambda x: x["score"], reverse=True)
    
    logger.info(f"ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: {len(scored_chunks)} ä»¶ (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords})")
    return scored_chunks[:k]


def rerank_chunks(
    query: str,
    chunks: List[Dict[str, Any]],
    top_k: int = None
) -> List[Dict[str, Any]]:
    """
    LLMã‚’ä½¿ã£ã¦æ¤œç´¢çµæœã‚’å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    
    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        chunks: æ¤œç´¢çµæœãƒãƒ£ãƒ³ã‚¯
        top_k: ä¸Šä½kä»¶ã‚’è¿”ã™ï¼ˆNoneã®å ´åˆã¯å…¨ã¦ï¼‰
    
    Returns:
        å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
    """
    if not chunks or len(chunks) <= 1:
        return chunks
    
    try:
        # ãƒãƒ£ãƒ³ã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æº–å‚™
        chunk_texts = []
        for i, chunk in enumerate(chunks):
            text = chunk.get("text", "")[:300]  # å…ˆé ­300æ–‡å­—
            chunk_texts.append(f"[{i+1}] {text}")
        
        system_prompt = """ã‚ãªãŸã¯æ¤œç´¢çµæœã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
æ¤œç´¢ã‚¯ã‚¨ãƒªã«é–¢é€£æ€§ãŒé«˜ã„é †ã«ã€ãƒãƒ£ãƒ³ã‚¯ã®ç•ªå·ã‚’ä¸¦ã³æ›¿ãˆã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ç‚¹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ï¼š
- æ¤œç´¢ã‚¯ã‚¨ãƒªã®æ„å›³ã«æœ€ã‚‚é–¢é€£ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸Šä½ã«
- é–¢é€£æ€§ã®ä½ã„ãƒãƒ£ãƒ³ã‚¯ã¯ä¸‹ä½ã«
- ç•ªå·ã®ã¿ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¿”ã™ï¼ˆä¾‹: 3,1,2,4ï¼‰"""
        
        user_message = f"""æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}

æ¤œç´¢çµæœ:
{chr(10).join(chunk_texts)}

ä¸Šè¨˜ã®æ¤œç´¢çµæœã‚’ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã«é–¢é€£æ€§ãŒé«˜ã„é †ã«ä¸¦ã³æ›¿ãˆã¦ãã ã•ã„ã€‚
ç•ªå·ã®ã¿ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¿”ã—ã¦ãã ã•ã„ï¼ˆä¾‹: 3,1,2,4ï¼‰ã€‚"""
        
        result = chat(
            messages=[{"role": "user", "content": user_message}],
            system=system_prompt,
            temperature=0.1,
            max_tokens=50
        )
        
        # ç•ªå·ã‚’æŠ½å‡º
        numbers = re.findall(r'\d+', result)
        if numbers:
            indices = [int(n) - 1 for n in numbers if 1 <= int(n) <= len(chunks)]
            if len(indices) == len(chunks):
                # é‡è¤‡é™¤å»ã—ã¦é †åºã‚’ä¿æŒ
                seen = set()
                reranked = []
                for idx in indices:
                    if idx not in seen:
                        seen.add(idx)
                        reranked.append(chunks[idx])
                # æ®‹ã‚Šã‚’è¿½åŠ 
                for i, chunk in enumerate(chunks):
                    if i not in seen:
                        reranked.append(chunk)
                
                logger.info(f"ğŸ”„ å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°: {len(reranked)} ä»¶")
                if top_k:
                    return reranked[:top_k]
                return reranked
    except Exception as e:
        logger.warning(f"âš ï¸  å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®é †åºã‚’è¿”ã™
    if top_k:
        return chunks[:top_k]
    return chunks


def retrieve_chunks(
    question: str,
    pos: int,
    k: int = 8,
    window: int = 3,
    history: List[Dict[str, str]] = None,
    character_name: str = None,
    use_query_expansion: bool = True,
    use_hybrid_search: bool = True,
    use_reranking: bool = True
) -> Tuple[List[Dict[str, Any]], str]:
    """
    è³ªå•ã¨ä½ç½®ã«åŸºã¥ã„ã¦ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆæ”¹å–„ç‰ˆï¼‰

    Args:
        question: è³ªå•æ–‡
        pos: ç¾åœ¨ä½ç½®
        k: å–å¾—ãƒãƒ£ãƒ³ã‚¯æ•°
        window: è¿‘å‚ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
        history: ä¼šè©±å±¥æ­´ [{"role": "user/assistant", "content": "..."}]
        character_name: å¯¾è©±ç›¸æ‰‹ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å
        use_query_expansion: è³ªå•æ‹¡å¼µã‚’ä½¿ç”¨ã™ã‚‹ã‹
        use_hybrid_search: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        use_reranking: å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ã‹

    Returns:
        (chunks, method): ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆã¨ä½¿ç”¨ã—ãŸæ¤œç´¢æ–¹æ³•
    """
    # ç¾åœ¨ã®ã‚·ãƒ¼ãƒ³ã‚’ç‰¹å®š
    current_scene = find_current_scene(pos)
    logger.info(f"ğŸ“ ç¾åœ¨ä½ç½®: pos={pos}, scene={current_scene}")

    # è¿‘å‚ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å–å¾—
    nearby = retrieve_nearby(current_scene, window=window)
    logger.info(f"ğŸ“¦ è¿‘å‚ãƒãƒ£ãƒ³ã‚¯: {len(nearby)} ä»¶")

    # è³ªå•ã®æ‹¡å¼µãƒ»ãƒªãƒ©ã‚¤ãƒˆï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æƒ…å ±ã¨ãƒ†ã‚­ã‚¹ãƒˆä½ç½®ã‚’è€ƒæ…®ï¼‰
    search_query = question
    if use_query_expansion:
        search_query = expand_query_with_history(
            question=question,
            history=history,
            character_name=character_name,
            pos=pos
        )

    logger.info(f"ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: '{search_query}'")

    # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
    query_vec = embed(search_query)
    semantic_results = search_semantic_qdrant(query_vec, k=k*2, max_pos=pos)  # å¤šã‚ã«å–å¾—
    method = "qdrant"

    # Qdrantæ¤œç´¢ãŒå¤±æ•—ã—ãŸã€ã¾ãŸã¯çµæœãŒ0ä»¶ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if semantic_results is None or len(semantic_results) == 0:
        logger.info("âš ï¸  Qdrantæ¤œç´¢çµæœãŒ0ä»¶ã®ãŸã‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
        semantic_results = search_semantic_fallback(query_vec, k=k*2, max_pos=pos)
        method = "fallback"

    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚‚å®Ÿè¡Œ
    keyword_results = []
    if use_hybrid_search:
        keyword_results = search_keyword(search_query, k=k, max_pos=pos)
        logger.info(f"ğŸ”‘ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: {len(keyword_results)} ä»¶")

    # è¿‘å‚ + ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµæœã‚’çµ±åˆï¼ˆé‡è¤‡é™¤å»ï¼‰
    seen_scenes = set()
    combined = []
    scene_to_chunk = {}  # ã‚·ãƒ¼ãƒ³ã”ã¨ã®æœ€è‰¯ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿æŒ

    # è¿‘å‚ãƒãƒ£ãƒ³ã‚¯ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ï¼ˆè³ªå•ã¨ã®é–¢é€£åº¦ãŒé«˜ã„ã‚‚ã®ã ã‘è¿½åŠ ï¼‰
    nearby_with_scores = []
    for chunk in nearby:
        if chunk["start_pos"] <= pos <= chunk["end_pos"] or chunk["end_pos"] <= pos:
            # è³ªå•ã¨ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—
            chunk_text = chunk.get("text", "")
            chunk_vec = embed(chunk_text)
            similarity = cosine_similarity([query_vec], [chunk_vec])[0][0]
            chunk["nearby_similarity"] = similarity
            nearby_with_scores.append((chunk, similarity))

    # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆã—ã¦ã€é–¢é€£åº¦ã®é«˜ã„è¿‘å‚ãƒãƒ£ãƒ³ã‚¯ã®ã¿ä¿æŒ
    nearby_with_scores.sort(key=lambda x: x[1], reverse=True)

    # é¡ä¼¼åº¦ãŒä¸€å®šä»¥ä¸Šï¼ˆ0.7ä»¥ä¸Šï¼‰ã€ã¾ãŸã¯ä¸Šä½2ä»¶ã®ã¿è¿½åŠ 
    nearby_threshold = 0.7
    nearby_added = 0
    for i, (chunk, similarity) in enumerate(nearby_with_scores):
        # ä¸Šä½2ä»¶ã€ã¾ãŸã¯é¡ä¼¼åº¦0.7ä»¥ä¸Šã®ãƒãƒ£ãƒ³ã‚¯ã®ã¿è¿½åŠ 
        if i < 2 or similarity >= nearby_threshold:
            scene_idx = chunk["scene_index"]
            if scene_idx not in seen_scenes:
                seen_scenes.add(scene_idx)
                chunk["source"] = "nearby"
                chunk["score"] = similarity + 0.2  # è¿‘å‚ãƒœãƒ¼ãƒŠã‚¹ã‚’å‰Šæ¸›ï¼ˆ0.5â†’0.2ï¼‰
                scene_to_chunk[scene_idx] = chunk
                nearby_added += 1
                logger.info(f"   ğŸ“Œ è¿‘å‚ãƒãƒ£ãƒ³ã‚¯è¿½åŠ  (similarity={similarity:.3f}): scene={scene_idx}")
        else:
            logger.info(f"   â­ï¸  è¿‘å‚ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ— (similarity={similarity:.3f} < {nearby_threshold}): scene={scene_idx}")

    logger.info(f"ğŸ“Œ è¿‘å‚ãƒãƒ£ãƒ³ã‚¯è¿½åŠ : {nearby_added}/{len(nearby)} ä»¶")

    # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢çµæœã‚’è¿½åŠ 
    for chunk in semantic_results:
        scene_idx = chunk["scene_index"]
        if scene_idx not in seen_scenes:
            seen_scenes.add(scene_idx)
            chunk["source"] = "semantic"
            scene_to_chunk[scene_idx] = chunk
        else:
            # æ—¢å­˜ã®ãƒãƒ£ãƒ³ã‚¯ãŒã‚ã‚‹å ´åˆã€ã‚¹ã‚³ã‚¢ãŒé«˜ã„æ–¹ã‚’ä¿æŒ
            existing = scene_to_chunk[scene_idx]
            if chunk.get("score", 0) > existing.get("score", 0):
                chunk["source"] = "semantic"
                scene_to_chunk[scene_idx] = chunk

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢çµæœã‚’è¿½åŠ 
    for chunk in keyword_results:
        scene_idx = chunk["scene_index"]
        if scene_idx not in seen_scenes:
            seen_scenes.add(scene_idx)
            chunk["source"] = "keyword"
            scene_to_chunk[scene_idx] = chunk
        else:
            # æ—¢å­˜ã®ãƒãƒ£ãƒ³ã‚¯ãŒã‚ã‚‹å ´åˆã€ã‚¹ã‚³ã‚¢ã‚’åŠ ç®—
            existing = scene_to_chunk[scene_idx]
            existing["score"] = existing.get("score", 0) + chunk.get("score", 0) * 0.3
            existing["source"] = existing.get("source", "") + "+keyword"

    combined = list(scene_to_chunk.values())
    
    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    combined.sort(key=lambda x: x.get("score", 0), reverse=True)

    # å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    if use_reranking and len(combined) > 2:
        combined = rerank_chunks(search_query, combined, top_k=k*2)

    # ä¸Šä½ k ä»¶ã«åˆ¶é™
    combined = combined[:k]

    logger.info(f"âœ… æœ€çµ‚å–å¾—: {len(combined)} ä»¶ (method={method})")
    return combined, method


def retrieve_relevant_events(
    current_scene: int,
    chunks: List[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """
    ç¾åœ¨ã®ã‚·ãƒ¼ãƒ³ã¨å–å¾—ã—ãŸãƒãƒ£ãƒ³ã‚¯ã«é–¢é€£ã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—

    pos ã‚ˆã‚Šæœªæ¥ã®ã‚¤ãƒ™ãƒ³ãƒˆã¯é™¤å¤–
    """
    events = get_events_cache()

    # å–å¾—ã—ãŸãƒãƒ£ãƒ³ã‚¯ã® scene ç¯„å›²
    scene_indices = {c["scene_index"] for c in chunks}
    min_scene = min(scene_indices) if scene_indices else current_scene
    max_scene = current_scene  # ç¾åœ¨ä½ç½®ã¾ã§

    relevant = []
    for event in events:
        first = event.get("first_scene")
        last = event.get("last_scene")

        if first is None or last is None:
            continue

        # ã‚¤ãƒ™ãƒ³ãƒˆã®ç¯„å›²ãŒ max_scene ä»¥å‰ã§ã€ã‹ã¤å–å¾—ç¯„å›²ã¨é‡ãªã‚‹
        if last <= max_scene and first <= max_scene:
            # é‡ãªã‚Šãƒã‚§ãƒƒã‚¯
            if first <= max_scene and last >= min_scene:
                relevant.append(event)

    logger.info(f"ğŸ“… é–¢é€£ã‚¤ãƒ™ãƒ³ãƒˆ: {len(relevant)} ä»¶")
    return relevant[:5]  # æœ€å¤§5ä»¶


def get_current_situation(
    pos: int,
    character_name: str,
    window: int = 5
) -> str:
    """
    æŒ‡å®šã•ã‚ŒãŸä½ç½®ä»˜è¿‘ã§ã€æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã‹ã‚’å–å¾—ã—ã€è¦ç´„ã—ã¦è¿”ã™

    Args:
        pos: ç¾åœ¨ã®æ–‡å­—ä½ç½®
        character_name: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å
        window: æ¤œç´¢ã™ã‚‹å‰å¾Œã®ã‚·ãƒ¼ãƒ³æ•°

    Returns:
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®çŠ¶æ³ã‚’è¦ç´„ã—ãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¸¸ã«ä½•ã‹ã—ã‚‰ã®çµæœã‚’è¿”ã™ï¼‰
    """
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ­ãƒƒã‚¯ä»˜ãï¼šåŒä¸€ã‚­ãƒ¼ã®ä¸¦è¡ŒLLMå‘¼ã³å‡ºã—ã‚’é˜²æ­¢ï¼‰
    cache_key = (pos, character_name)
    if cache_key in _situation_cache:
        logger.info(f"âœ“ {character_name}ã®çŠ¶æ³è¦ç´„ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾— (pos={pos})")
        return _situation_cache[cache_key]

    with _situation_locks_guard:
        # ãƒ€ãƒ–ãƒ«ãƒã‚§ãƒƒã‚¯ï¼šã‚¬ãƒ¼ãƒ‰å–å¾—ä¸­ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒåŸ‹ã¾ã£ãŸå ´åˆ
        if cache_key in _situation_cache:
            return _situation_cache[cache_key]
        if cache_key in _situation_locks:
            # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ãŒå‡¦ç†ä¸­ â†’ å®Œäº†ã‚’å¾…ã¤
            event = _situation_locks[cache_key]
        else:
            # è‡ªåˆ†ãŒå‡¦ç†ã‚’æ‹…å½“ã™ã‚‹
            event = threading.Event()
            _situation_locks[cache_key] = event
            event = None  # None = è‡ªåˆ†ãŒå‡¦ç†æ‹…å½“ã®å°

    if event is not None:
        # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã®å®Œäº†ã‚’å¾…æ©Ÿ
        logger.info(f"â³ {character_name}ã®çŠ¶æ³è¦ç´„ã‚’åˆ¥ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒå‡¦ç†ä¸­ã€å¾…æ©Ÿã—ã¾ã™ (pos={pos})")
        event.wait()
        if cache_key in _situation_cache:
            return _situation_cache[cache_key]
        # å‡¦ç†æ‹…å½“ã‚¹ãƒ¬ãƒƒãƒ‰ãŒå¤±æ•—ã—ãŸå ´åˆã€è‡ªåˆ†ã§å†å®Ÿè¡Œï¼ˆä¸‹ã«ç¶šè¡Œï¼‰

    chunks = get_chunks_cache()
    current_scene = find_current_scene(pos)

    # ç¾åœ¨ä½ç½®ä»˜è¿‘ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆposä»¥å‰ã®ã¿ï¼‰
    nearby_chunks = []
    for chunk in chunks:
        # posã‚’å«ã‚€ãƒãƒ£ãƒ³ã‚¯ã€ã¾ãŸã¯posä»¥å‰ã§çµ‚ã‚ã‚‹ãƒãƒ£ãƒ³ã‚¯
        if (chunk["start_pos"] <= pos <= chunk["end_pos"] or chunk["end_pos"] <= pos):
            # ç¾åœ¨ã‚·ãƒ¼ãƒ³ã®å‰å¾Œwindowå†…
            if abs(chunk["scene_index"] - current_scene) <= window:
                # æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒç™»å ´ã—ã¦ã„ã‚‹ãƒãƒ£ãƒ³ã‚¯
                if character_name in chunk.get("characters", []):
                    nearby_chunks.append(chunk)

    # ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€windowã‚’åºƒã’ã¦å†æ¤œç´¢
    if not nearby_chunks:
        logger.info(f"âš ï¸  {character_name}ã®è¿‘å‚ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€windowã‚’æ‹¡å¤§ã—ã¦å†æ¤œç´¢")
        expanded_window = window * 2
        for chunk in chunks:
            if (chunk["start_pos"] <= pos <= chunk["end_pos"] or chunk["end_pos"] <= pos):
                if abs(chunk["scene_index"] - current_scene) <= expanded_window:
                    if character_name in chunk.get("characters", []):
                        nearby_chunks.append(chunk)

    # ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ç¾åœ¨ä½ç½®ä»˜è¿‘ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŒ‡å®šãªã—ï¼‰
    if not nearby_chunks:
        logger.info(f"âš ï¸  {character_name}ã®ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ç¾åœ¨ä½ç½®ä»˜è¿‘ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½¿ç”¨")
        for chunk in chunks:
            if (chunk["start_pos"] <= pos <= chunk["end_pos"] or chunk["end_pos"] <= pos):
                if abs(chunk["scene_index"] - current_scene) <= window:
                    nearby_chunks.append(chunk)

    # æœ€ã‚‚è¿‘ã„ãƒãƒ£ãƒ³ã‚¯ï¼ˆposã«æœ€ã‚‚è¿‘ã„ï¼‰ã‚’å„ªå…ˆã—ã¦ã‚½ãƒ¼ãƒˆ
    nearby_chunks.sort(key=lambda c: abs(c["start_pos"] - pos))

    # æœ€å¤§3ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é›†ã‚ã‚‹ï¼ˆè¿‘ã„ã‚‚ã®ã‹ã‚‰ï¼‰
    relevant_texts = []
    for chunk in nearby_chunks[:3]:
        text = chunk.get("text", "").strip()
        if text:
            relevant_texts.append(text)

    # ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã§ã‚‚ã€ç¾åœ¨ä½ç½®ä»˜è¿‘ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    if not relevant_texts:
        logger.warning(f"âš ï¸  {character_name}ã®é–¢é€£ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç¾åœ¨ä½ç½®ä»˜è¿‘ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨")
        # ç¾åœ¨ä½ç½®ã‚’å«ã‚€ãƒãƒ£ãƒ³ã‚¯ã‚’æ¢ã™
        for chunk in chunks:
            if chunk["start_pos"] <= pos <= chunk["end_pos"]:
                text = chunk.get("text", "").strip()
                if text:
                    relevant_texts.append(text[:500])  # å…ˆé ­500æ–‡å­—
                    break

    # ãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
    combined_text = "\n\n".join(relevant_texts) if relevant_texts else ""

    # è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆï¼ˆç‰¹å®šã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’æŒ‡å®šã›ãšã€ç´”ç²‹ã«ç¾åœ¨ã®çŠ¶æ³ã‚’è¦ç´„ï¼‰
    system_prompt = """ã‚ãªãŸã¯å°èª¬ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ†ã‚­ã‚¹ãƒˆè¿‘å‚ã§ä½•ãŒèµ·ã“ã£ã¦ã„ã‚‹ã®ã‹ã‚’æ•´ç†ã—ã€ç™»å ´ã—ã¦ã„ã‚‹äººç‰©ã”ã¨ã«ã€èª°ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã®ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ç‚¹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ï¼š
- ãƒ†ã‚­ã‚¹ãƒˆè¿‘å‚ã§ä½•ãŒèµ·ã“ã£ã¦ã„ã‚‹ã®ã‹ã‚’æ•´ç†ã™ã‚‹ï¼ˆå ´é¢ã®çŠ¶æ³ã€å‡ºæ¥äº‹ã®æµã‚Œãªã©ï¼‰
- ç™»å ´ã—ã¦ã„ã‚‹äººç‰©ã‚’ç‰¹å®šã—ã€ãã‚Œãã‚Œã®äººç‰©ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã®ã‹ã€ã©ã®ã‚ˆã†ãªè¡Œå‹•ã‚’å–ã£ã¦ã„ã‚‹ã®ã‹ã‚’å…·ä½“çš„ã«èª¬æ˜ã™ã‚‹
- å„äººç‰©ã®çŠ¶æ³ã‚„å¿ƒç†çŠ¶æ…‹ã‚‚å«ã‚ã¦èª¬æ˜ã™ã‚‹
- äººç‰©ã”ã¨ã«åˆ†ã‘ã¦èª¬æ˜ã™ã‚‹ï¼ˆä¾‹ï¼šã€Œäººç‰©A: ...ã€ã€Œäººç‰©B: ...ã€ã®ã‚ˆã†ãªå½¢å¼ï¼‰
- ç°¡æ½”ã™ããšã€å¿…è¦ãªæƒ…å ±ã‚’å«ã‚ã¦èª¬æ˜ã™ã‚‹ï¼ˆ100-200æ–‡å­—ç¨‹åº¦ã‚’ç›®å®‰ï¼‰"""

    user_message = f"""ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€ãƒ†ã‚­ã‚¹ãƒˆè¿‘å‚ã§ä½•ãŒèµ·ã“ã£ã¦ã„ã‚‹ã®ã‹ã‚’æ•´ç†ã—ã€ç™»å ´ã—ã¦ã„ã‚‹äººç‰©ã”ã¨ã«ã€èª°ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã®ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

{combined_text}"""

    # è¦ç´„ã«ä½¿ç”¨ã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
    logger.info("=" * 60)
    logger.info(f"ğŸ“ {character_name}ã®çŠ¶æ³è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡:")
    logger.info(f"   ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
    logger.info(f"   {system_prompt}")
    logger.info(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:")
    logger.info(f"   {user_message}")
    logger.info("=" * 60)

    try:
        # è»½é‡ãªãƒ¢ãƒ‡ãƒ«ã§è¦ç´„ï¼ˆgpt-4o-miniã‚’ä½¿ç”¨ã€max_tokensã‚’å¢—ã‚„ã—ã¦è©³ç´°ãªèª¬æ˜ã‚’å¯èƒ½ã«ã™ã‚‹ï¼‰
        summary = chat(
            messages=[{"role": "user", "content": user_message}],
            system=system_prompt,
            temperature=0.3,
            max_tokens=300
        )
        result = summary.strip()
        if not result:
            result = "ç¾åœ¨ä½ç½®ä»˜è¿‘ã®çŠ¶æ³ã¯ä¸æ˜"
        logger.info(f"âœ“ {character_name}ã®çŠ¶æ³è¦ç´„çµæœ: {result[:50]}...")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        _situation_cache[cache_key] = result
        return result
    except Exception as e:
        logger.error(f"âŒ è¦ç´„ã‚¨ãƒ©ãƒ¼ ({character_name}): {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã®ä¸€éƒ¨ã‚’è¿”ã™
        if relevant_texts:
            fallback_text = relevant_texts[0]
            if len(fallback_text) > 200:
                fallback_text = fallback_text[:200] + "..."
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯çµæœã‚‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            _situation_cache[cache_key] = fallback_text
            return fallback_text
        else:
            # ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™
            default_msg = "ç¾åœ¨ä½ç½®ä»˜è¿‘ã®çŠ¶æ³ã¯ä¸æ˜"
            _situation_cache[cache_key] = default_msg
            return default_msg
    finally:
        # å¾…æ©Ÿä¸­ã‚¹ãƒ¬ãƒƒãƒ‰ã«å®Œäº†ã‚’é€šçŸ¥ã—ã€ãƒ­ãƒƒã‚¯ã‚’è§£æ”¾
        with _situation_locks_guard:
            ev = _situation_locks.pop(cache_key, None)
        if ev is not None:
            ev.set()
