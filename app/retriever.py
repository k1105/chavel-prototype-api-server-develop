"""
æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆRAGï¼‰

pos ä»¥å‰ã®ãƒãƒ£ãƒ³ã‚¯ã®ã¿ã‚’æ¤œç´¢å¯¾è±¡ã¨ã—ã€ãƒã‚¿ãƒãƒ¬ã‚’é˜²æ­¢
"""

import logging
import re
from typing import List, Dict, Any, Optional, Tuple

import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

from app.utils import get_chunks_cache, get_events_cache, embed, chat

logger = logging.getLogger(__name__)

# Qdrant ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ï¼‰
_qdrant_client = None
COLLECTION_NAME = "neko_scenes"


def get_qdrant_client():
    """Qdrant ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’å–å¾—ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰"""
    global _qdrant_client
    if _qdrant_client is None:
        try:
            from qdrant_client import QdrantClient
            _qdrant_client = QdrantClient(host="localhost", port=6333)
            # æ¥ç¶šãƒ†ã‚¹ãƒˆ
            _qdrant_client.get_collections()
            logger.info("âœ“ Qdrant æ¥ç¶šæˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸  Qdrant æ¥ç¶šå¤±æ•—: {e}")
            _qdrant_client = False  # å¤±æ•—ã‚’è¨˜éŒ²
    return _qdrant_client if _qdrant_client is not False else None


def find_current_scene(pos: int) -> Optional[int]:
    """pos ã‚’å«ã‚€/æœ€ã‚‚è¿‘ã„ãƒãƒ£ãƒ³ã‚¯ã® scene_index ã‚’è¿”ã™"""
    chunks = get_chunks_cache()

    # pos ã‚’å«ã‚€ãƒãƒ£ãƒ³ã‚¯ã‚’æ¢ã™
    for chunk in chunks:
        if chunk["start_pos"] <= pos <= chunk["end_pos"]:
            return chunk["scene_index"]

    # å«ã¾ã‚Œãªã„å ´åˆã€æœ€ã‚‚è¿‘ã„ãƒãƒ£ãƒ³ã‚¯ã‚’æ¢ã™
    closest = min(chunks, key=lambda c: abs(c["start_pos"] - pos))
    return closest["scene_index"]


def retrieve_nearby(scene: int, window: int = 3) -> List[Dict[str, Any]]:
    """scene ã®å‰å¾Œ window ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—"""
    chunks = get_chunks_cache()

    nearby = []
    for chunk in chunks:
        if scene - window <= chunk["scene_index"] <= scene + window:
            nearby.append(chunk)

    return nearby


def search_semantic_qdrant(
    query_vec: List[float],
    k: int,
    max_pos: int
) -> Optional[List[Dict[str, Any]]]:
    """Qdrant ã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆpos ãƒ•ã‚£ãƒ«ã‚¿ä»˜ãï¼‰"""
    client = get_qdrant_client()
    if client is None:
        return None

    try:
        from qdrant_client.models import FieldCondition, Filter, Range

        # max_pos ã‚’å«ã‚€ãƒãƒ£ãƒ³ã‚¯ã€ã¾ãŸã¯ max_pos ä»¥å‰ã§çµ‚ã‚ã‚‹ãƒãƒ£ãƒ³ã‚¯
        # start_pos <= max_pos ã®ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆend_pos <= max_pos ã¾ãŸã¯ start_pos <= max_pos <= end_posï¼‰
        query_filter = Filter(
            must=[
                FieldCondition(
                    key="start_pos",
                    range=Range(lte=max_pos)
                )
            ]
        )

        results = client.search(
            collection_name=COLLECTION_NAME,
            query_vector=query_vec,
            query_filter=query_filter,
            limit=k
        )

        chunks = []
        for hit in results:
            chunk_data = {
                "scene_index": hit.payload["scene_index"],
                "chapter": hit.payload["chapter"],
                "start_pos": hit.payload["start_pos"],
                "end_pos": hit.payload["end_pos"],
                "text": hit.payload["text"],
                "characters": hit.payload.get("characters", []),
                "score": hit.score
            }
            chunks.append(chunk_data)

        logger.info(f"âœ“ Qdrant æ¤œç´¢: {len(chunks)} ä»¶å–å¾—")
        return chunks

    except Exception as e:
        logger.error(f"âŒ Qdrant æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def search_semantic_fallback(
    query_vec: List[float],
    k: int,
    max_pos: int
) -> List[Dict[str, Any]]:
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦æ¤œç´¢"""
    chunks = get_chunks_cache()

    # max_pos ã‚’å«ã‚€ãƒãƒ£ãƒ³ã‚¯ã€ã¾ãŸã¯ max_pos ä»¥å‰ã§çµ‚ã‚ã‚‹ãƒãƒ£ãƒ³ã‚¯
    candidates = [c for c in chunks if c["start_pos"] <= max_pos <= c["end_pos"] or c["end_pos"] <= max_pos]

    if not candidates:
        logger.warning("âš ï¸  max_pos ä»¥å‰ã®ãƒãƒ£ãƒ³ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“")
        return []

    # å„ãƒãƒ£ãƒ³ã‚¯ã‚’åŸ‹ã‚è¾¼ã¿
    logger.info(f"ğŸ“Š ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢: {len(candidates)} ä»¶ã‹ã‚‰åŸ‹ã‚è¾¼ã¿è¨ˆç®—ä¸­...")
    chunk_vecs = []
    for chunk in candidates:
        try:
            vec = embed(chunk["text"][:500])  # å…ˆé ­500æ–‡å­—
            chunk_vecs.append(vec)
        except Exception as e:
            logger.error(f"åŸ‹ã‚è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            chunk_vecs.append([0.0] * len(query_vec))  # ãƒ€ãƒŸãƒ¼

    # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®—
    query_vec_np = np.array(query_vec).reshape(1, -1)
    chunk_vecs_np = np.array(chunk_vecs)

    similarities = cosine_similarity(query_vec_np, chunk_vecs_np)[0]

    # ä¸Šä½ k ä»¶
    top_indices = np.argsort(similarities)[::-1][:k]

    results = []
    for idx in top_indices:
        chunk = candidates[idx].copy()
        chunk["score"] = float(similarities[idx])
        results.append(chunk)

    logger.info(f"âœ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢: {len(results)} ä»¶å–å¾—")
    return results


def expand_query_with_history(question: str, history: List[Dict[str, str]] = None) -> str:
    """
    ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ã¦è³ªå•ã‚’æ‹¡å¼µãƒ»ãƒªãƒ©ã‚¤ãƒˆ
    
    Args:
        question: ç¾åœ¨ã®è³ªå•
        history: ä¼šè©±å±¥æ­´ [{"role": "user/assistant", "content": "..."}]
    
    Returns:
        æ‹¡å¼µã•ã‚ŒãŸè³ªå•æ–‡
    """
    if not history or len(history) == 0:
        return question
    
    # ç›´è¿‘ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—ï¼ˆæœ€å¤§3ã‚¿ãƒ¼ãƒ³ï¼‰
    recent_history = history[-6:] if len(history) > 6 else history
    
    # å±¥æ­´ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„æ–‡è„ˆã‚’æŠ½å‡º
    history_context = ""
    for msg in recent_history:
        role = msg.get("role", "")
        content = msg.get("content", "")
        if content:
            history_context += f"{content}\n"
    
    # LLMã‚’ä½¿ã£ã¦è³ªå•ã‚’æ‹¡å¼µãƒ»ãƒªãƒ©ã‚¤ãƒˆ
    try:
        system_prompt = """ã‚ãªãŸã¯æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ”¹å–„ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä¼šè©±å±¥æ­´ã¨ç¾åœ¨ã®è³ªå•ã‚’è€ƒæ…®ã—ã¦ã€ã‚ˆã‚Šæ¤œç´¢ã«é©ã—ãŸè³ªå•æ–‡ã«ãƒªãƒ©ã‚¤ãƒˆã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ç‚¹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ï¼š
- ä¼šè©±å±¥æ­´ã®æ–‡è„ˆã‚’è€ƒæ…®ã™ã‚‹
- è³ªå•ã®æ„å›³ã‚’æ˜ç¢ºã«ã™ã‚‹
- å…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹
- ç°¡æ½”ã§æ¤œç´¢ã«é©ã—ãŸå½¢ã«ã™ã‚‹ï¼ˆ50æ–‡å­—ä»¥å†…ã‚’ç›®å®‰ï¼‰
- å…ƒã®è³ªå•ã®æ„å›³ã‚’å¤‰ãˆãªã„"""
        
        user_message = f"""ä¼šè©±å±¥æ­´:
{history_context}

ç¾åœ¨ã®è³ªå•: {question}

ä¸Šè¨˜ã®ä¼šè©±å±¥æ­´ã¨ç¾åœ¨ã®è³ªå•ã‚’è€ƒæ…®ã—ã¦ã€ã‚ˆã‚Šæ¤œç´¢ã«é©ã—ãŸè³ªå•æ–‡ã«ãƒªãƒ©ã‚¤ãƒˆã—ã¦ãã ã•ã„ã€‚"""
        
        expanded = chat(
            messages=[{"role": "user", "content": user_message}],
            system=system_prompt,
            temperature=0.3,
            max_tokens=100
        )
        
        expanded = expanded.strip()
        if expanded and len(expanded) > 10:  # æœ‰åŠ¹ãªçµæœã®å ´åˆ
            logger.info(f"ğŸ“ è³ªå•æ‹¡å¼µ: '{question}' â†’ '{expanded}'")
            return expanded
    except Exception as e:
        logger.warning(f"âš ï¸  è³ªå•æ‹¡å¼µã‚¨ãƒ©ãƒ¼: {e}")
    
    return question


def search_keyword(
    query: str,
    k: int,
    max_pos: int
) -> List[Dict[str, Any]]:
    """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆç°¡æ˜“ç‰ˆï¼šãƒ†ã‚­ã‚¹ãƒˆå†…ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ï¼‰
    
    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        k: å–å¾—ä»¶æ•°
        max_pos: æœ€å¤§ä½ç½®
    
    Returns:
        æ¤œç´¢çµæœãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
    """
    chunks = get_chunks_cache()
    
    # max_posä»¥å‰ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    candidates = [c for c in chunks if c["start_pos"] <= max_pos]
    
    if not candidates:
        return []
    
    # ã‚¯ã‚¨ãƒªã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆæ—¥æœ¬èªã®å˜èªå¢ƒç•Œã‚’è€ƒæ…®ï¼‰
    keywords = []
    # åè©ã‚„é‡è¦ãã†ãªå˜èªã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼š2æ–‡å­—ä»¥ä¸Šã®é€£ç¶šæ–‡å­—ï¼‰
    words = re.findall(r'[ä¸€-é¾¥ã-ã‚“ã‚¡-ãƒ³]{2,}', query)
    keywords.extend(words)
    
    # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å‡ºç¾å›æ•°ï¼‰
    scored_chunks = []
    for chunk in candidates:
        text = chunk.get("text", "")
        score = 0
        matched_keywords = []
        
        for keyword in keywords:
            count = text.count(keyword)
            if count > 0:
                score += count
                matched_keywords.append(keyword)
        
        if score > 0:
            chunk_copy = chunk.copy()
            chunk_copy["score"] = float(score)
            chunk_copy["matched_keywords"] = matched_keywords
            scored_chunks.append(chunk_copy)
    
    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    scored_chunks.sort(key=lambda x: x["score"], reverse=True)
    
    logger.info(f"ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: {len(scored_chunks)} ä»¶ (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords})")
    return scored_chunks[:k]


def rerank_chunks(
    query: str,
    chunks: List[Dict[str, Any]],
    top_k: int = None
) -> List[Dict[str, Any]]:
    """
    LLMã‚’ä½¿ã£ã¦æ¤œç´¢çµæœã‚’å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    
    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        chunks: æ¤œç´¢çµæœãƒãƒ£ãƒ³ã‚¯
        top_k: ä¸Šä½kä»¶ã‚’è¿”ã™ï¼ˆNoneã®å ´åˆã¯å…¨ã¦ï¼‰
    
    Returns:
        å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
    """
    if not chunks or len(chunks) <= 1:
        return chunks
    
    try:
        # ãƒãƒ£ãƒ³ã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æº–å‚™
        chunk_texts = []
        for i, chunk in enumerate(chunks):
            text = chunk.get("text", "")[:300]  # å…ˆé ­300æ–‡å­—
            chunk_texts.append(f"[{i+1}] {text}")
        
        system_prompt = """ã‚ãªãŸã¯æ¤œç´¢çµæœã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
æ¤œç´¢ã‚¯ã‚¨ãƒªã«é–¢é€£æ€§ãŒé«˜ã„é †ã«ã€ãƒãƒ£ãƒ³ã‚¯ã®ç•ªå·ã‚’ä¸¦ã³æ›¿ãˆã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ç‚¹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ï¼š
- æ¤œç´¢ã‚¯ã‚¨ãƒªã®æ„å›³ã«æœ€ã‚‚é–¢é€£ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸Šä½ã«
- é–¢é€£æ€§ã®ä½ã„ãƒãƒ£ãƒ³ã‚¯ã¯ä¸‹ä½ã«
- ç•ªå·ã®ã¿ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¿”ã™ï¼ˆä¾‹: 3,1,2,4ï¼‰"""
        
        user_message = f"""æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}

æ¤œç´¢çµæœ:
{chr(10).join(chunk_texts)}

ä¸Šè¨˜ã®æ¤œç´¢çµæœã‚’ã€æ¤œç´¢ã‚¯ã‚¨ãƒªã«é–¢é€£æ€§ãŒé«˜ã„é †ã«ä¸¦ã³æ›¿ãˆã¦ãã ã•ã„ã€‚
ç•ªå·ã®ã¿ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§è¿”ã—ã¦ãã ã•ã„ï¼ˆä¾‹: 3,1,2,4ï¼‰ã€‚"""
        
        result = chat(
            messages=[{"role": "user", "content": user_message}],
            system=system_prompt,
            temperature=0.1,
            max_tokens=50
        )
        
        # ç•ªå·ã‚’æŠ½å‡º
        numbers = re.findall(r'\d+', result)
        if numbers:
            indices = [int(n) - 1 for n in numbers if 1 <= int(n) <= len(chunks)]
            if len(indices) == len(chunks):
                # é‡è¤‡é™¤å»ã—ã¦é †åºã‚’ä¿æŒ
                seen = set()
                reranked = []
                for idx in indices:
                    if idx not in seen:
                        seen.add(idx)
                        reranked.append(chunks[idx])
                # æ®‹ã‚Šã‚’è¿½åŠ 
                for i, chunk in enumerate(chunks):
                    if i not in seen:
                        reranked.append(chunk)
                
                logger.info(f"ğŸ”„ å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°: {len(reranked)} ä»¶")
                if top_k:
                    return reranked[:top_k]
                return reranked
    except Exception as e:
        logger.warning(f"âš ï¸  å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®é †åºã‚’è¿”ã™
    if top_k:
        return chunks[:top_k]
    return chunks


def retrieve_chunks(
    question: str,
    pos: int,
    k: int = 8,
    window: int = 3,
    history: List[Dict[str, str]] = None,
    use_query_expansion: bool = True,
    use_hybrid_search: bool = True,
    use_reranking: bool = True
) -> Tuple[List[Dict[str, Any]], str]:
    """
    è³ªå•ã¨ä½ç½®ã«åŸºã¥ã„ã¦ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆæ”¹å–„ç‰ˆï¼‰

    Args:
        question: è³ªå•æ–‡
        pos: ç¾åœ¨ä½ç½®
        k: å–å¾—ãƒãƒ£ãƒ³ã‚¯æ•°
        window: è¿‘å‚ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
        history: ä¼šè©±å±¥æ­´ [{"role": "user/assistant", "content": "..."}]
        use_query_expansion: è³ªå•æ‹¡å¼µã‚’ä½¿ç”¨ã™ã‚‹ã‹
        use_hybrid_search: ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        use_reranking: å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ã‹

    Returns:
        (chunks, method): ãƒãƒ£ãƒ³ã‚¯ãƒªã‚¹ãƒˆã¨ä½¿ç”¨ã—ãŸæ¤œç´¢æ–¹æ³•
    """
    # ç¾åœ¨ã®ã‚·ãƒ¼ãƒ³ã‚’ç‰¹å®š
    current_scene = find_current_scene(pos)
    logger.info(f"ğŸ“ ç¾åœ¨ä½ç½®: pos={pos}, scene={current_scene}")

    # è¿‘å‚ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦å–å¾—
    nearby = retrieve_nearby(current_scene, window=window)
    logger.info(f"ğŸ“¦ è¿‘å‚ãƒãƒ£ãƒ³ã‚¯: {len(nearby)} ä»¶")

    # è³ªå•ã®æ‹¡å¼µãƒ»ãƒªãƒ©ã‚¤ãƒˆ
    search_query = question
    if use_query_expansion and history:
        search_query = expand_query_with_history(question, history)
    
    logger.info(f"ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒª: '{search_query}'")

    # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
    query_vec = embed(search_query)
    semantic_results = search_semantic_qdrant(query_vec, k=k*2, max_pos=pos)  # å¤šã‚ã«å–å¾—
    method = "qdrant"

    # Qdrantæ¤œç´¢ãŒå¤±æ•—ã—ãŸã€ã¾ãŸã¯çµæœãŒ0ä»¶ã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if semantic_results is None or len(semantic_results) == 0:
        logger.info("âš ï¸  Qdrantæ¤œç´¢çµæœãŒ0ä»¶ã®ãŸã‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œç´¢ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
        semantic_results = search_semantic_fallback(query_vec, k=k*2, max_pos=pos)
        method = "fallback"

    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚‚å®Ÿè¡Œ
    keyword_results = []
    if use_hybrid_search:
        keyword_results = search_keyword(search_query, k=k, max_pos=pos)
        logger.info(f"ğŸ”‘ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: {len(keyword_results)} ä»¶")

    # è¿‘å‚ + ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ + ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰çµæœã‚’çµ±åˆï¼ˆé‡è¤‡é™¤å»ï¼‰
    seen_scenes = set()
    combined = []
    scene_to_chunk = {}  # ã‚·ãƒ¼ãƒ³ã”ã¨ã®æœ€è‰¯ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿æŒ

    # è¿‘å‚ã‚’å„ªå…ˆ
    nearby_added = 0
    for chunk in nearby:
        if chunk["start_pos"] <= pos <= chunk["end_pos"] or chunk["end_pos"] <= pos:
            scene_idx = chunk["scene_index"]
            if scene_idx not in seen_scenes:
                seen_scenes.add(scene_idx)
                chunk["source"] = "nearby"
                chunk["score"] = chunk.get("score", 1.0) + 0.5  # è¿‘å‚ã¯ãƒœãƒ¼ãƒŠã‚¹
                scene_to_chunk[scene_idx] = chunk
                nearby_added += 1
    logger.info(f"ğŸ“Œ è¿‘å‚ãƒãƒ£ãƒ³ã‚¯è¿½åŠ : {nearby_added}/{len(nearby)} ä»¶")

    # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢çµæœã‚’è¿½åŠ 
    for chunk in semantic_results:
        scene_idx = chunk["scene_index"]
        if scene_idx not in seen_scenes:
            seen_scenes.add(scene_idx)
            chunk["source"] = "semantic"
            scene_to_chunk[scene_idx] = chunk
        else:
            # æ—¢å­˜ã®ãƒãƒ£ãƒ³ã‚¯ãŒã‚ã‚‹å ´åˆã€ã‚¹ã‚³ã‚¢ãŒé«˜ã„æ–¹ã‚’ä¿æŒ
            existing = scene_to_chunk[scene_idx]
            if chunk.get("score", 0) > existing.get("score", 0):
                chunk["source"] = "semantic"
                scene_to_chunk[scene_idx] = chunk

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢çµæœã‚’è¿½åŠ 
    for chunk in keyword_results:
        scene_idx = chunk["scene_index"]
        if scene_idx not in seen_scenes:
            seen_scenes.add(scene_idx)
            chunk["source"] = "keyword"
            scene_to_chunk[scene_idx] = chunk
        else:
            # æ—¢å­˜ã®ãƒãƒ£ãƒ³ã‚¯ãŒã‚ã‚‹å ´åˆã€ã‚¹ã‚³ã‚¢ã‚’åŠ ç®—
            existing = scene_to_chunk[scene_idx]
            existing["score"] = existing.get("score", 0) + chunk.get("score", 0) * 0.3
            existing["source"] = existing.get("source", "") + "+keyword"

    combined = list(scene_to_chunk.values())
    
    # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
    combined.sort(key=lambda x: x.get("score", 0), reverse=True)

    # å†ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    if use_reranking and len(combined) > 2:
        combined = rerank_chunks(search_query, combined, top_k=k*2)

    # ä¸Šä½ k ä»¶ã«åˆ¶é™
    combined = combined[:k]

    logger.info(f"âœ… æœ€çµ‚å–å¾—: {len(combined)} ä»¶ (method={method})")
    return combined, method


def retrieve_relevant_events(
    current_scene: int,
    chunks: List[Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """
    ç¾åœ¨ã®ã‚·ãƒ¼ãƒ³ã¨å–å¾—ã—ãŸãƒãƒ£ãƒ³ã‚¯ã«é–¢é€£ã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—

    pos ã‚ˆã‚Šæœªæ¥ã®ã‚¤ãƒ™ãƒ³ãƒˆã¯é™¤å¤–
    """
    events = get_events_cache()

    # å–å¾—ã—ãŸãƒãƒ£ãƒ³ã‚¯ã® scene ç¯„å›²
    scene_indices = {c["scene_index"] for c in chunks}
    min_scene = min(scene_indices) if scene_indices else current_scene
    max_scene = current_scene  # ç¾åœ¨ä½ç½®ã¾ã§

    relevant = []
    for event in events:
        first = event.get("first_scene")
        last = event.get("last_scene")

        if first is None or last is None:
            continue

        # ã‚¤ãƒ™ãƒ³ãƒˆã®ç¯„å›²ãŒ max_scene ä»¥å‰ã§ã€ã‹ã¤å–å¾—ç¯„å›²ã¨é‡ãªã‚‹
        if last <= max_scene and first <= max_scene:
            # é‡ãªã‚Šãƒã‚§ãƒƒã‚¯
            if first <= max_scene and last >= min_scene:
                relevant.append(event)

    logger.info(f"ğŸ“… é–¢é€£ã‚¤ãƒ™ãƒ³ãƒˆ: {len(relevant)} ä»¶")
    return relevant[:5]  # æœ€å¤§5ä»¶


def get_current_situation(
    pos: int,
    character_name: str,
    window: int = 5
) -> str:
    """
    æŒ‡å®šã•ã‚ŒãŸä½ç½®ä»˜è¿‘ã§ã€æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã‹ã‚’å–å¾—ã—ã€è¦ç´„ã—ã¦è¿”ã™

    Args:
        pos: ç¾åœ¨ã®æ–‡å­—ä½ç½®
        character_name: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å
        window: æ¤œç´¢ã™ã‚‹å‰å¾Œã®ã‚·ãƒ¼ãƒ³æ•°

    Returns:
        ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®çŠ¶æ³ã‚’è¦ç´„ã—ãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¸¸ã«ä½•ã‹ã—ã‚‰ã®çµæœã‚’è¿”ã™ï¼‰
    """
    chunks = get_chunks_cache()
    current_scene = find_current_scene(pos)

    # ç¾åœ¨ä½ç½®ä»˜è¿‘ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆposä»¥å‰ã®ã¿ï¼‰
    nearby_chunks = []
    for chunk in chunks:
        # posã‚’å«ã‚€ãƒãƒ£ãƒ³ã‚¯ã€ã¾ãŸã¯posä»¥å‰ã§çµ‚ã‚ã‚‹ãƒãƒ£ãƒ³ã‚¯
        if (chunk["start_pos"] <= pos <= chunk["end_pos"] or chunk["end_pos"] <= pos):
            # ç¾åœ¨ã‚·ãƒ¼ãƒ³ã®å‰å¾Œwindowå†…
            if abs(chunk["scene_index"] - current_scene) <= window:
                # æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒç™»å ´ã—ã¦ã„ã‚‹ãƒãƒ£ãƒ³ã‚¯
                if character_name in chunk.get("characters", []):
                    nearby_chunks.append(chunk)

    # ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€windowã‚’åºƒã’ã¦å†æ¤œç´¢
    if not nearby_chunks:
        logger.info(f"âš ï¸  {character_name}ã®è¿‘å‚ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€windowã‚’æ‹¡å¤§ã—ã¦å†æ¤œç´¢")
        expanded_window = window * 2
        for chunk in chunks:
            if (chunk["start_pos"] <= pos <= chunk["end_pos"] or chunk["end_pos"] <= pos):
                if abs(chunk["scene_index"] - current_scene) <= expanded_window:
                    if character_name in chunk.get("characters", []):
                        nearby_chunks.append(chunk)

    # ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ç¾åœ¨ä½ç½®ä»˜è¿‘ã®ãƒãƒ£ãƒ³ã‚¯ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼æŒ‡å®šãªã—ï¼‰
    if not nearby_chunks:
        logger.info(f"âš ï¸  {character_name}ã®ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ç¾åœ¨ä½ç½®ä»˜è¿‘ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½¿ç”¨")
        for chunk in chunks:
            if (chunk["start_pos"] <= pos <= chunk["end_pos"] or chunk["end_pos"] <= pos):
                if abs(chunk["scene_index"] - current_scene) <= window:
                    nearby_chunks.append(chunk)

    # æœ€ã‚‚è¿‘ã„ãƒãƒ£ãƒ³ã‚¯ï¼ˆposã«æœ€ã‚‚è¿‘ã„ï¼‰ã‚’å„ªå…ˆã—ã¦ã‚½ãƒ¼ãƒˆ
    nearby_chunks.sort(key=lambda c: abs(c["start_pos"] - pos))

    # æœ€å¤§3ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é›†ã‚ã‚‹ï¼ˆè¿‘ã„ã‚‚ã®ã‹ã‚‰ï¼‰
    relevant_texts = []
    for chunk in nearby_chunks[:3]:
        text = chunk.get("text", "").strip()
        if text:
            relevant_texts.append(text)

    # ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã§ã‚‚ã€ç¾åœ¨ä½ç½®ä»˜è¿‘ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
    if not relevant_texts:
        logger.warning(f"âš ï¸  {character_name}ã®é–¢é€£ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç¾åœ¨ä½ç½®ä»˜è¿‘ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨")
        # ç¾åœ¨ä½ç½®ã‚’å«ã‚€ãƒãƒ£ãƒ³ã‚¯ã‚’æ¢ã™
        for chunk in chunks:
            if chunk["start_pos"] <= pos <= chunk["end_pos"]:
                text = chunk.get("text", "").strip()
                if text:
                    relevant_texts.append(text[:500])  # å…ˆé ­500æ–‡å­—
                    break

    # ãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
    combined_text = "\n\n".join(relevant_texts) if relevant_texts else ""

    # è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆï¼ˆç‰¹å®šã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’æŒ‡å®šã›ãšã€ç´”ç²‹ã«ç¾åœ¨ã®çŠ¶æ³ã‚’è¦ç´„ï¼‰
    system_prompt = """ã‚ãªãŸã¯å°èª¬ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ†ã‚­ã‚¹ãƒˆè¿‘å‚ã§ä½•ãŒèµ·ã“ã£ã¦ã„ã‚‹ã®ã‹ã‚’æ•´ç†ã—ã€ç™»å ´ã—ã¦ã„ã‚‹äººç‰©ã”ã¨ã«ã€èª°ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã®ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®ç‚¹ã‚’é‡è¦–ã—ã¦ãã ã•ã„ï¼š
- ãƒ†ã‚­ã‚¹ãƒˆè¿‘å‚ã§ä½•ãŒèµ·ã“ã£ã¦ã„ã‚‹ã®ã‹ã‚’æ•´ç†ã™ã‚‹ï¼ˆå ´é¢ã®çŠ¶æ³ã€å‡ºæ¥äº‹ã®æµã‚Œãªã©ï¼‰
- ç™»å ´ã—ã¦ã„ã‚‹äººç‰©ã‚’ç‰¹å®šã—ã€ãã‚Œãã‚Œã®äººç‰©ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã®ã‹ã€ã©ã®ã‚ˆã†ãªè¡Œå‹•ã‚’å–ã£ã¦ã„ã‚‹ã®ã‹ã‚’å…·ä½“çš„ã«èª¬æ˜ã™ã‚‹
- å„äººç‰©ã®çŠ¶æ³ã‚„å¿ƒç†çŠ¶æ…‹ã‚‚å«ã‚ã¦èª¬æ˜ã™ã‚‹
- äººç‰©ã”ã¨ã«åˆ†ã‘ã¦èª¬æ˜ã™ã‚‹ï¼ˆä¾‹ï¼šã€Œäººç‰©A: ...ã€ã€Œäººç‰©B: ...ã€ã®ã‚ˆã†ãªå½¢å¼ï¼‰
- ç°¡æ½”ã™ããšã€å¿…è¦ãªæƒ…å ±ã‚’å«ã‚ã¦èª¬æ˜ã™ã‚‹ï¼ˆ100-200æ–‡å­—ç¨‹åº¦ã‚’ç›®å®‰ï¼‰"""

    user_message = f"""ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€ãƒ†ã‚­ã‚¹ãƒˆè¿‘å‚ã§ä½•ãŒèµ·ã“ã£ã¦ã„ã‚‹ã®ã‹ã‚’æ•´ç†ã—ã€ç™»å ´ã—ã¦ã„ã‚‹äººç‰©ã”ã¨ã«ã€èª°ãŒä½•ã‚’ã—ã¦ã„ã‚‹ã®ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

{combined_text}"""

    # è¦ç´„ã«ä½¿ç”¨ã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
    logger.info("=" * 60)
    logger.info(f"ğŸ“ {character_name}ã®çŠ¶æ³è¦ç´„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¨æ–‡:")
    logger.info(f"   ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
    logger.info(f"   {system_prompt}")
    logger.info(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:")
    logger.info(f"   {user_message}")
    logger.info("=" * 60)

    try:
        # è»½é‡ãªãƒ¢ãƒ‡ãƒ«ã§è¦ç´„ï¼ˆgpt-4o-miniã‚’ä½¿ç”¨ã€max_tokensã‚’å¢—ã‚„ã—ã¦è©³ç´°ãªèª¬æ˜ã‚’å¯èƒ½ã«ã™ã‚‹ï¼‰
        summary = chat(
            messages=[{"role": "user", "content": user_message}],
            system=system_prompt,
            temperature=0.3,
            max_tokens=300
        )
        result = summary.strip()
        if not result:
            result = "ç¾åœ¨ä½ç½®ä»˜è¿‘ã®çŠ¶æ³ã¯ä¸æ˜"
        logger.info(f"âœ“ {character_name}ã®çŠ¶æ³è¦ç´„çµæœ: {result[:50]}...")
        return result
    except Exception as e:
        logger.error(f"âŒ è¦ç´„ã‚¨ãƒ©ãƒ¼ ({character_name}): {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šæœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã®ä¸€éƒ¨ã‚’è¿”ã™
        if relevant_texts:
            fallback_text = relevant_texts[0]
            if len(fallback_text) > 200:
                fallback_text = fallback_text[:200] + "..."
            return fallback_text
        else:
            # ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™
            return "ç¾åœ¨ä½ç½®ä»˜è¿‘ã®çŠ¶æ³ã¯ä¸æ˜"
